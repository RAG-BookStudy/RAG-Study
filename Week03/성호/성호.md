# 성호 3주차 학습내용

## 프롬프트 엔지니어링 핵심 개념

### In-Context Learning (ICL)

LLM이 **프롬프트 내의 예제로부터 패턴을 학습**하는 현상 <br>
→ 파라미터 업데이트 없이 프롬프트만으로 태스크 수행 능력 향상

**ICL의 작동 원리**
> - LLM은 사전학습 과정에서 다양한 패턴을 학습
> - 프롬프트에 예제를 제공하면, 해당 패턴을 "활성화"
> - 예제의 형식/구조를 모방하여 새로운 입력에 적용

**예제 개수에 따른 분류**
| 방식 | 설명 |
| ---- | ---- |
| Zero-shot | 예제 없이 태스크 설명만으로 수행 |
| One-shot | 예제 1개 제공 |
| Few-shot | 예제 2~5개 제공 (가장 효과적) |

※ 예제가 많다고 무조건 좋은 것은 아님 <br>
→ 컨텍스트 윈도우 한계 + 관련 없는 예제는 오히려 성능 저하

<br>

---

## Chain of Thought (CoT) 프롬프팅

복잡한 추론이 필요한 문제에서 **중간 단계를 명시적으로 생성**하도록 유도 <br>
→ 단순히 답만 요구하는 것보다 정확도가 크게 향상

### CoT가 효과적인 이유

> - LLM은 토큰을 순차적으로 생성 → 이전 출력이 다음 출력에 영향
> - 중간 추론 단계가 "작업 메모리" 역할을 수행
> - 복잡한 문제를 작은 하위 문제로 분해하는 효과

### CoT 예제 구조

```
Q: 스티브 잡스와 아인슈타인 중 누가 더 오래 살았나요?

A: 이 질문에 추가 질문이 필요한가요: 예.
추가 질문: 스티브 잡스는 몇 살에 사망했나요?
중간 답변: 56세에 사망했습니다.
추가 질문: 아인슈타인은 몇 살에 사망했나요?
중간 답변: 76세에 사망했습니다.
최종 답변: 아인슈타인
```

→ 이런 형식의 예제를 Few-shot으로 제공하면, 모델이 동일한 추론 패턴을 따름

<br>

---

## FewShotPromptTemplate

예제를 프롬프트에 포함시켜 **In-Context Learning**을 활용

```python
from langchain_core.prompts.few_shot import FewShotPromptTemplate
from langchain_core.prompts import PromptTemplate

examples = [
    {
        "question": "스티브 잡스와 아인슈타인 중 누가 더 오래 살았나요?",
        "answer": """추가 질문: 스티브 잡스는 몇 살에 사망했나요?
중간 답변: 56세에 사망했습니다.
추가 질문: 아인슈타인은 몇 살에 사망했나요?
중간 답변: 76세에 사망했습니다.
최종 답변: 아인슈타인""",
    },
    # ... 더 많은 예제
]

example_prompt = PromptTemplate.from_template(
    "Question:\n{question}\nAnswer:\n{answer}"
)

prompt = FewShotPromptTemplate(
    examples=examples,
    example_prompt=example_prompt,
    suffix="Question:\n{question}\nAnswer:",
    input_variables=["question"],
)
```

<br>

---

## Example Selector (의미론적 유사도 기반)

### 왜 필요한가?

> - 예제가 많으면 컨텍스트 윈도우 초과 위험
> - **관련성 높은 예제**가 성능에 더 중요
> - 입력과 유사한 예제만 동적으로 선택

### 작동 원리

```
1. 모든 예제를 임베딩 벡터로 변환 → VectorStore에 저장
2. 새로운 입력이 들어오면 입력도 임베딩
3. 코사인 유사도로 가장 유사한 k개 예제 검색
4. 검색된 예제만 프롬프트에 포함
```

```python
from langchain_core.example_selectors import SemanticSimilarityExampleSelector
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma

example_selector = SemanticSimilarityExampleSelector.from_examples(
    examples,                    # 예시 목록
    OpenAIEmbeddings(),         # 임베딩 모델
    Chroma,                     # VectorStore
    k=1,                        # 선택할 예시 개수
)

# FewShotPromptTemplate에서 examples 대신 사용
prompt = FewShotPromptTemplate(
    example_selector=example_selector,
    example_prompt=example_prompt,
    suffix="Question:\n{question}\nAnswer:",
    input_variables=["question"],
)
```

### 주의사항

※ 기본 SemanticSimilarityExampleSelector는 **모든 필드를 합쳐서** 유사도 계산 <br>
→ `instruction` 필드만으로 검색하고 싶은 경우 잘못된 예제가 선택될 수 있음 <br>
→ 이 경우 `CustomExampleSelector`로 특정 필드만 사용하도록 커스터마이징 필요

<br>

---

## MessagesPlaceholder

### 용도: 대화 기록(Memory) 동적 주입

LLM은 **stateless** → 이전 대화를 기억하지 못함 <br>
→ 매 요청마다 이전 대화 내역을 프롬프트에 포함시켜야 함

```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

chat_prompt = ChatPromptTemplate.from_messages([
    ("system", "당신은 친절한 AI 어시스턴트입니다."),
    MessagesPlaceholder(variable_name="chat_history"),  # 대화 기록 삽입 위치
    ("human", "{user_input}"),
])
```

### 실제 활용 패턴

```
[System] 당신은 친절한 AI 어시스턴트입니다.
[Human] 안녕하세요!                    ← chat_history[0]
[AI] 안녕하세요! 무엇을 도와드릴까요?    ← chat_history[1]
[Human] 파이썬 설치 방법 알려줘          ← chat_history[2]
[AI] 파이썬 공식 사이트에서...          ← chat_history[3]
[Human] {user_input}                   ← 현재 입력
```

→ `MessagesPlaceholder`는 대화가 길어질수록 chat_history가 커짐 <br>
→ 컨텍스트 윈도우 관리를 위해 오래된 대화는 요약하거나 삭제하는 전략 필요

<br>

---

## partial_variables: 동적 변수 주입

**호출 시점에 값이 결정되는 변수**에 활용 <br>
→ 날짜, 시간, 세션 정보 등

```python
from datetime import datetime

def get_today():
    return datetime.now().strftime("%B %d")

prompt = PromptTemplate(
    template="오늘 날짜는 {today}입니다. {question}",
    input_variables=["question"],
    partial_variables={"today": get_today},  # 함수 전달 → invoke 시점에 호출
)
```

> - 값을 직접 전달: 고정값
> - 함수를 전달: 매 호출마다 함수 실행 결과 사용

<br>

---

## 궁금한 점 & 답변

### Q1. Few-shot 예제는 몇 개가 최적인가?

**A:** 일반적으로 **2~5개**가 권장됨

> - 1개(One-shot): 패턴 인식에 부족할 수 있음
> - 2~5개(Few-shot): 패턴을 충분히 학습하면서 컨텍스트 효율적
> - 5개 이상: 수확 체감 + 컨텍스트 윈도우 낭비

※ 중요한 것은 **예제의 품질과 다양성** <br>
→ 비슷한 예제 10개보다 다양한 케이스 3개가 더 효과적

<br>

### Q2. CoT는 모든 문제에 효과적인가?

**A:** 아니다. **복잡한 추론이 필요한 경우**에만 효과적

| 문제 유형 | CoT 효과 |
| --------- | -------- |
| 수학/논리 문제 | 매우 효과적 |
| 다단계 추론 필요 | 효과적 |
| 단순 사실 질문 | 불필요 (오히려 비효율) |
| 창작/생성 태스크 | 효과 제한적 |

→ "대한민국 수도는?" 같은 단순 질문에 CoT 적용하면 토큰 낭비

<br>

### Q3. Zero-shot vs Few-shot, 언제 뭘 써야 하나?

**A:**

| 상황 | 권장 방식 |
| ---- | --------- |
| 모델이 이미 잘 하는 일반적 태스크 | Zero-shot |
| 특정 형식/포맷이 필요한 경우 | Few-shot |
| 도메인 특화 태스크 | Few-shot |
| 토큰 비용 절약이 중요할 때 | Zero-shot |
| 정확도가 가장 중요할 때 | Few-shot |

※ 먼저 Zero-shot으로 테스트 → 결과가 불만족스러우면 Few-shot 적용

<br>

### Q4. 대화 기록이 길어지면 어떻게 관리하나?

**A:** 주요 전략 3가지

> 1. **Sliding Window**: 최근 N개 메시지만 유지, 오래된 것은 삭제
> 2. **요약 방식**: 오래된 대화를 LLM으로 요약하여 압축 저장
> 3. **토큰 기반 제한**: 총 토큰 수가 한계에 도달하면 오래된 것부터 삭제

```
[전체 대화 100턴]
     ↓ 요약
[요약: "사용자는 파이썬 설치 후 가상환경 설정까지 완료함"]
[최근 대화 10턴]
[현재 입력]
```

→ 실제 서비스에서는 **요약 + Sliding Window** 조합을 많이 사용

<br>

### Q5. Example Selector의 k값은 어떻게 정하나?

**A:** 트레이드오프 고려

> - k가 크면: 더 많은 예제 참고 → 정확도 ↑, 토큰 비용 ↑
> - k가 작으면: 적은 예제 → 비용 ↓, 관련성 높은 예제만 사용

**실용적 가이드:**
- 짧은 예제: k=2~3
- 긴 예제(CoT 등): k=1~2
- 컨텍스트 윈도우의 **20~30%**를 예제에 할당하는 것이 적정

※ 정답은 없음 → 실험으로 최적값 찾아야 함
