# 성호 4주차 학습내용

## 목차
- [Chapter 6. 출력 파서 & 구조화 응답](#chapter-6-출력-파서--구조화-응답)
  - [왜 Output Parser가 필요한가?](#왜-output-parser가-필요한가)
  - [직접 해보니 느낀 점](#직접-해보니-느낀-점)
  - [PydanticOutputParser 실습](#pydanticoutputparser-실습)
  - [헷갈렸던 부분: partial()과 invoke()](#헷갈렸던-부분-partial과-invoke)
  - [LLM이 형식을 안 지키면?](#llm이-형식을-안-지키면)
- [이번 주 핵심 정리](#이번-주-핵심-정리)
- [더 공부해볼 것](#더-공부해볼-것)

---

## Chapter 6. 출력 파서 & 구조화 응답

### 왜 Output Parser가 필요한가?

처음에 이 챕터 시작할 때 솔직히 의문이 들었다.

> "그냥 프롬프트에 'JSON으로 답해줘'라고 하면 되는 거 아닌가?"

실제로 해봤다. ChatGPT한테 "영화 평점을 JSON으로 줘"라고 하면 대충 JSON처럼 생긴 걸 준다. 근데 문제는:

1. **가끔 마크다운 코드블록으로 감싸서 줌** → 파싱 에러
2. **필드명이 일정하지 않음** → `title`이었다가 `movie_title`이었다가...
3. **타입이 들쭉날쭉** → 평점이 `"8"` (문자열)이었다가 `8` (숫자)였다가

결국 **"LLM 출력은 믿을 수 없다"**는 걸 깨달았다. 그래서 Output Parser가 필요하다.

**Output Parser가 해주는 것:**
- 프롬프트에 **정확한 형식 가이드**를 넣어줌
- 출력을 받아서 **실제 Python 객체로 변환**
- 형식이 틀리면 **에러를 던져서** 알려줌

---

### 직접 해보니 느낀 점

LangChain에서 제공하는 파서 종류가 꽤 많다. 처음엔 뭘 써야 할지 몰랐는데, 정리해보니 이렇다:

| 상황 | 추천 파서 | 이유 |
|:---|:---|:---|
| 복잡한 객체가 필요할 때 | `PydanticOutputParser` | 타입 검증이 강력함 |
| 단순히 리스트만 필요할 때 | `CommaSeparatedListOutputParser` | 가볍고 빠름 |
| 빠르게 테스트할 때 | `StructuredOutputParser` | 설정이 간단함 |

내 경우엔 거의 **PydanticOutputParser**만 쓰게 될 것 같다. 이유는:
- 어차피 Python 쓰면 Pydantic은 거의 필수로 쓰게 됨 (FastAPI 등)
- IDE 자동완성이 됨 → 개발 편의성
- 나중에 API 응답으로 바로 쓸 수 있음

---

### PydanticOutputParser 실습

직접 만들어본 예시. 책 리뷰를 구조화해서 받아보기:

```python
from langchain_core.output_parsers import PydanticOutputParser
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from pydantic import BaseModel, Field
from typing import List

# 내가 원하는 출력 형태를 Pydantic으로 정의
class BookReview(BaseModel):
    book_title: str = Field(description="책 제목")
    author: str = Field(description="저자")
    rating: int = Field(description="1~5점 사이의 평점")
    pros: List[str] = Field(description="장점 목록")
    cons: List[str] = Field(description="단점 목록")
    one_line: str = Field(description="한줄평")

# 파서 생성
parser = PydanticOutputParser(pydantic_object=BookReview)

# 프롬프트 구성
prompt = PromptTemplate(
    template="""
다음 책에 대한 리뷰를 작성해주세요.

책: {book_name}

{format_instructions}
""",
    input_variables=["book_name"],
    partial_variables={"format_instructions": parser.get_format_instructions()}
)

# 체인 실행
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
chain = prompt | llm | parser

result = chain.invoke({"book_name": "클린 코드"})
print(result.book_title)  # "클린 코드"
print(result.rating)      # 5
print(result.pros)        # ["가독성 향상", "유지보수 용이", ...]
```

**실습하면서 깨달은 것:**
- `Field(description=...)`이 중요하다. 이게 프롬프트에 들어가서 LLM이 뭘 넣어야 하는지 알게 됨
- `temperature=0`으로 해야 형식을 잘 지킴. 높이면 창의적(?)으로 형식 무시함

---

### 헷갈렸던 부분: partial()과 invoke()

처음에 코드 보면서 헷갈렸던 게 있다:

```python
# 방법 1: partial 사용
prompt = prompt.partial(format_instructions=parser.get_format_instructions())
chain.invoke({"book_name": "클린 코드"})

# 방법 2: 그냥 invoke에 다 넣기
chain.invoke({
    "book_name": "클린 코드",
    "format_instructions": parser.get_format_instructions()
})
```

둘 다 동작은 한다. 근데 뭐가 다른가?

**내가 이해한 차이:**

| | partial() | invoke()에 다 넣기 |
|:---|:---|:---|
| **언제 값이 정해지나** | 체인 만들 때 (1번) | 실행할 때마다 |
| **적합한 값** | 안 변하는 것 | 매번 바뀌는 것 |
| **예시** | format_instructions | 사용자 질문 |

`format_instructions`는 파서가 바뀌지 않는 이상 계속 같은 값이다. 그래서 `partial()`로 미리 박아두는 게 맞다. 반면 사용자 질문은 매번 다르니까 `invoke()`로 넘긴다.

> 쉽게 생각하면: **고정값은 partial, 변동값은 invoke**

---

### LLM이 형식을 안 지키면?

이게 제일 골치 아픈 문제다. 아무리 프롬프트에 형식을 알려줘도 LLM이 가끔 이상하게 답변한다.

예를 들어 rating에 `"5점"` 이렇게 문자열로 주면? → ValidationError 터짐

**대응 방법 3가지:**

#### 1. 그냥 try-except로 처리

```python
try:
    result = parser.parse(output)
except Exception as e:
    print(f"파싱 실패: {e}")
    result = None  # 또는 기본값
```

가장 단순하지만, 실패하면 그냥 끝이다.

#### 2. OutputFixingParser (자동 수정)

```python
from langchain.output_parsers import OutputFixingParser

fixing_parser = OutputFixingParser.from_llm(
    parser=parser,
    llm=ChatOpenAI(temperature=0)
)

# 형식이 틀리면 LLM이 다시 고쳐줌
result = fixing_parser.parse(wrong_output)
```

이건 출력이 틀리면 **LLM한테 "이거 형식 틀렸어, 고쳐줘"**라고 다시 요청하는 방식이다.

**장점:** 자동으로 복구됨
**단점:** API 호출이 한 번 더 일어남 → 돈과 시간

#### 3. RetryOutputParser (재시도)

```python
from langchain.output_parsers import RetryOutputParser

retry_parser = RetryOutputParser.from_llm(
    parser=parser,
    llm=ChatOpenAI(temperature=0),
    max_retries=3
)
```

이건 OutputFixingParser랑 비슷한데, **원래 프롬프트까지 같이 줘서** 다시 시도한다. 맥락을 더 많이 줘서 성공 확률이 높다고 한다.

**내 생각:** 프로덕션에서는 비용 때문에 OutputFixingParser까지만 쓰고, 그래도 실패하면 로깅하고 기본값 반환하는 게 현실적일 듯.

---

## 이번 주 핵심 정리

1. **LLM 출력은 불안정하다** → Output Parser로 구조화 필수
2. **Pydantic이 가장 강력하다** → 타입 검증 + IDE 지원
3. **partial()은 고정값, invoke()는 변동값**
4. **파싱 실패 대비는 필수** → OutputFixingParser 또는 try-except

---

## 더 공부해볼 것

- [ ] `with_structured_output()` 메서드 → 더 간단하게 구조화 출력을 얻는 방법이 있다고 함
- [ ] JSON Mode (OpenAI) → `response_format={"type": "json_object"}` 옵션
- [ ] 실제 프로젝트에 적용해보기 → 챗봇 응답을 구조화해서 프론트엔드에 넘기기

---
