## 토큰과 토큰화 기초

**토큰**: 자연어 처리에서 텍스트를 처리하기 위해 나눈 작은 단위(단어, 서브워드, 문자)

**토큰화**: 텍스트를 토큰으로 나누는 과정

### 토큰화 방식 비교

**문자 기반 토큰화**: 텍스트를 개별 문자로 쪼개어 각 문자를 하나의 토큰으로 취급

`‘HELLO’` → `‘H’, ‘E’, ‘L’, ‘L’, ‘O’`

**단어 기반 토큰화**: 텍스트를 단어 단위로 나누는 방식

`‘HELLO WORLD!’` → `‘HELLO’, ‘WORLD’, ‘!’`

**서브워드 기반 토큰화**

`‘MACHINE LEARNING’ → ‘MA’, ‘CHINE’, ‘LEARN’, ‘ING’`

- **서브워드**:  단어보다 작은 단위로, 접두사, 접미사, 어근 등이 해당
- **바이트 페어 인코딩(BPE)**: 단어를 처음에 문자 단위로 분해한 후, 자주 등장하는 문자 쌍을 결합해 더 큰 서브워드로 만드는 방식
- **장점**
    - 문자 기반보다 토큰 수 적음 (효율적)
    - 단어 기반보다 유연함 (미등록 단어 처리 가능)
    - GPT, BERT 등 대부분의 최신 LLM이 사용

**왜 서브워드 방식을 사용하나?**

LLM은 먼저 나올 토큰을 생성하면 그 다음 나올 토큰을 확률적으로 계산해서 생성한다.

- 문자 기반: 토큰이 너무 많아 틀린 토큰 생성 확률 높음.
- 단어 기반: 미등록 단어(OOV) 처리 어려움
- 서브워드: 두 방식의 장점을 결합

### 한국어의 토큰 효율성

**같은 의미의 텍스트를 대상으로 했을 때 한글은 영어보다 토큰을 좀 더 소모한다.**

```python
# 토큰 수 비교
영어 100단어 ≈ 75 토큰
한국어 100단어 ≈ 150-200 토큰 # 약 2배
```

- API 비용 증가 (토큰당 과금)
- 컨텍스트 윈도우 빨리 소진
    - 컨텍스트 윈도우: 모델이 한 번에 처리하고 이해할 수 있는 전체 텍스트의 문맥 범위
    - 컨텍스트 길이: LLM이 한 번에 처리할 수 있는 입력과 출력의 총합 토큰 수
- 청킹 전략 조정 필요 (chunk_size를 더 크게)

**왜 한국어가 토큰을 더 소비할까?**

1. 교착어 특성: 조사가 붙어서 단어 변형이 많음
2. BPE 학습 데이터가 영어 중심
3. 한글 자모 조합의 다양성

## 한국어 RAG 처리 시 고려할 점

### 1. 임베딩 모델 선택

**문제점: 영어 중심 모델의 한계**

```python
# OpenAI text-embedding-ada-002 (영어 최적화)
"안녕하세요" vs "안녕" vs "안뇽"
→ 한국어 뉘앙스를 제대로 못 잡음

"배가 고프다" (hungry)
"배가 아프다" (stomach hurts)
→ "배"의 중의성을 제대로 이해 못할 수 있음
```

⇒ 한국어 특화 모델 사용

```python
from sentence_transformers import SentenceTransformer

# 1. KoSimCSE-roberta (한국어 특화)
model = SentenceTransformer('BM-K/KoSimCSE-roberta-multitask')

# 2. multilingual 모델 중 한국어 성능 좋은 것
model = SentenceTransformer('intfloat/multilingual-e5-large')

# 3. OpenAI 사용하더라도 text-embedding-3 시리즈
```

---

### 2. 토큰화(Tokenization) 문제

**한국어의 특수성: 교착어**

```python
# 청킹(chunking) 시 문제
# 영어: 띄어쓰기로 명확히 분리
"I love programming" → ["I", "love", "programming"]

# 한국어: 띄어쓰기 없으면 토큰이 비정상적으로 쪼개져서 의미 손실
"스프링부트는자바프레임워크입니다"

# 한국어: 조사가 붙어서 복잡
"프로그래밍을" → "프로그래밍" + "을"
"프로그래밍이" → "프로그래밍" + "이"
"프로그래밍으로" → "프로그래밍" + "으로"
# 토크나이저는 이걸 각각 다른 토큰으로 인식할 수 있음
```

**해결 방법**

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

# 한국어 문장 구분자 고려
splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50,
    separators=["\n\n", "\n", "。", ".", "!", "?", " ", ""],  # 한국어 구분자 추가
    length_function=len  # 문자 기준으로 계산
)
```

---

### 3. 띄어쓰기 & 맞춤법 전처리

```python
# 띄어쓰기가 엉망일 경우
user_query = "스프링부트에서제이피에이설정어떻게해"

# 띄어쓰기 전처리
from pykospacing import Spacing
spacing = Spacing()

cleaned_query = spacing(user_query)
# → "스프링 부트에서 JPA 설정 어떻게 해"

# 맞춤법 교정
from hanspell import spell_checker

result = spell_checker.check(user_query)
corrected = result.checked

```

---

### 4. 문서 청킹(Chunking) 전략

**한국어 문장 구조의 특징**

```python
# 문제 상황
original = """
Spring Boot는 Java 기반의 프레임워크입니다.
이 프레임워크는 설정이 간단합니다.
의존성 주입 기능도 제공합니다.
"""

# 잘못된 청킹 (문맥 끊김)
chunk1 = "Spring Boot는 Java 기반의 프레임워크입니다. 이"
chunk2 = "프레임워크는 설정이 간단합니다."
# "이" 로 시작하는 chunk2는 무슨 내용인지 알 수 없음

# 한국어는 주어 생략이 많아서 더 심각함
chunk1 = "JPA를 사용하면 편리합니다."
chunk2 = "복잡한 쿼리도 작성할 수 있습니다."
# "무엇이" 복잡한 쿼리를 작성하는지 주어가 없음

```

**개선 방법**

```python
# 1. 문단 단위로 청킹
splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,  # 한국어는 조금 크게
    chunk_overlap=200,  # overlap도 넉넉하게
    separators=["\n\n", "\n", ". ", "。", "! ", "? "]
)

# 2. 메타데이터 추가로 맥락 보존
chunks = [
    {
        "content": chunk_text,
        "metadata": {
            "title": "Spring Boot 설명서",  # 문서 제목
            "section": "2.3 JPA 설정",      # 섹션 정보
            "prev_sentence": "...",         # 이전 문장
        }
    }
]

# 3. 검색 시 메타데이터도 활용
retrieved_doc = """
[제목: Spring Boot 설명서 > JPA 설정]
{chunk_content}
"""

```

---

### 5. 검색 쿼리 전처리

**한국어 검색의 어려움**

```python
# 동일한 질문에 다양한 표현
queries = [
    "스프링부트 설정 방법",
    "Spring Boot 설정 방법",
    "스프링 부트 어떻게 설정해?",
    "스프링부트 세팅하는 법",
]

# 모두 같은 문서를 찾아야 하는데 임베딩만으로는 한계가 있을 수 있음
```

**검색 전략**

```python
from langchain.retrievers import EnsembleRetriever
from langchain.retrievers import BM25Retriever  # 키워드 기반

# 1. 벡터 검색 (의미적 유사도)
vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

# 2. 키워드 검색 (BM25 - 형태소 분석 활용)
from konlpy.tag import Okt
okt = Okt()

def korean_tokenizer(text):
    return okt.morphs(text)  # 형태소 분리

bm25_retriever = BM25Retriever.from_texts(
    documents,
    preprocess_func=korean_tokenizer  # 한국어 형태소 분석
)

# 3. 두 방식을 결합
ensemble_retriever = EnsembleRetriever(
    retrievers=[vector_retriever, bm25_retriever],
    weights=[0.5, 0.5]  # 벡터:키워드 = 5:5
)

# 결과: "스프링부트"와 "Spring Boot" 모두 잘 찾음
```

---

### 6. 프롬프트 엔지니어링

**한국어 특화 프롬프트**

```python
# 나쁜 예 → 한영 혼용으로 혼란
prompt = """
Answer based on context:
{context}

Question: {question}
"""
```

```python
# 좋은 예 → 한국어로 명확하게
prompt = """
다음 문맥을 참고하여 질문에 답변해주세요.

[참고 문맥]
{context}

[질문]
{question}

[답변 작성 규칙]
1. 반드시 제공된 문맥 내용만 사용하세요
2. 문맥에 없는 내용은 "제공된 자료에서 해당 정보를 찾을 수 없습니다"라고 답변하세요
3. 자연스러운 한국어 존댓말로 작성하세요
4. 전문 용어는 한글과 영문을 병기하세요 (예: 의존성 주입(Dependency Injection))
"""

# 더 좋은 예 → 구체적인 예시 제공
prompt_with_examples = """
다음은 좋은 답변의 예시입니다:

질문: "스프링 부트가 뭔가요?"
답변: "Spring Boot는 Java 기반의 웹 애플리케이션 프레임워크입니다.
설정을 자동화하여 개발자가 비즈니스 로직에 집중할 수 있도록 도와줍니다."

이제 다음 질문에 답변해주세요:
{question}
"""
```

---

## 코드 전체 예시

```python
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter

# 1. 한국어 임베딩 모델
embeddings = HuggingFaceEmbeddings(
    model_name="BM-K/KoSimCSE-roberta-multitask",
    model_kwargs={'device': 'cpu'}
)

# 2. 한국어 친화적 청킹
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    separators=["\n\n", "\n", "。", ". ", "! ", "? ", " ", ""],
)

# 3. 문서 로드 (학습 자료)
study_materials = """
객체지향 프로그래밍(OOP)의 4대 원칙은 다음과 같습니다.

1. 캡슐화(Encapsulation)
데이터와 메서드를 하나로 묶고, 외부에서 직접 접근하지 못하도록 보호합니다.
...
"""

chunks = text_splitter.split_text(study_materials)

# 4. 벡터 DB 저장
vectorstore = Chroma.from_texts(
    texts=chunks,
    embedding=embeddings,
    collection_name="OOP_study"
)

# 5. 검색
query = "OOP 특징이 뭐야?"
docs = vectorstore.similarity_search(query, k=3)

# 6. 답변 생성 (프롬프트에 한국어 컨텍스트 추가)
context = "\n".join([doc.page_content for doc in docs])
final_prompt = f"""
학습 자료를 바탕으로 학생의 질문에 친절하게 답변해주세요.

[학습 자료]
{context}

[학생 질문]
{query}

[답변 작성 시 주의사항]
- 존댓말 사용
- 이해하기 쉽게 설명
- 전문 용어는 한글과 영문 병기
"""

```